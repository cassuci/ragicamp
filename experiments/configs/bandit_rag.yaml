# Configuration for Bandit-based RAG

agent:
  type: bandit_rag
  name: "bandit_ucb_rag"
  system_prompt: "You are a helpful assistant. Use the provided context to answer questions accurately."

model:
  type: huggingface
  model_name: "google/flan-t5-base"
  device: "cuda"
  max_tokens: 128
  temperature: 0.7

retriever:
  type: dense
  name: "wikipedia_dense"
  embedding_model: "all-MiniLM-L6-v2"
  index_type: "flat"

policy:
  type: ucb
  name: "ucb_policy"
  c: 2.0  # Exploration parameter
  actions:
    # Different RAG parameter configurations to explore
    - top_k: 3
    - top_k: 5
    - top_k: 7
    - top_k: 10

dataset:
  name: natural_questions
  split: train
  num_examples: 1000  # Train on 1000 examples

training:
  num_epochs: 1
  eval_interval: 100

metrics:
  - exact_match
  - f1

output:
  save_predictions: true
  save_policy: true
  output_path: "outputs/bandit_rag_results.json"
  policy_path: "outputs/bandit_policy.json"

