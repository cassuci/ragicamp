# Natural Questions - Baseline (DirectLLM) with Gemma 2B
# Full evaluation with ALL metrics (including slower ones)

agent:
  type: direct_llm
  name: "gemma_2b_baseline_all_metrics"
  system_prompt: "You are a helpful AI assistant. Answer questions accurately and concisely based on your knowledge."

model:
  type: huggingface
  model_name: "google/gemma-2-2b-it"
  device: "cuda"
  load_in_8bit: true

dataset:
  name: natural_questions
  split: validation
  num_examples: 100
  filter_no_answer: true

# All available metrics with custom configurations
metrics:
  - exact_match
  - f1
  - name: bertscore
    params:
      model_type: "microsoft/deberta-base-mnli"  # Options: deberta-xlarge-mnli (slower, better)
  - name: bleurt
    params:
      checkpoint: "BLEURT-20"  # Options: BLEURT-20-D3 (faster), BLEURT-20 (better)
  
  # Note: Faithfulness/hallucination metrics require retrieved context
  # They are only meaningful for RAG agents (not baseline DirectLLM)
  # For RAG evaluation with faithfulness, see: nq_fixed_rag_with_faithfulness.yaml

output:
  save_predictions: true
  output_path: "outputs/nq_baseline_gemma2b_all_metrics.json"

